/*
       Copyright 2017 IBM Corp All Rights Reserved
       Copyright 2023 Kyndryl Corp, All Rights Reserved

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
 */

package com.ibm.hybrid.cloud.sample.stocktrader.portfolio;

import java.io.PrintWriter;
import java.io.StringWriter;
import java.net.ConnectException;
import java.util.Properties;
import java.util.concurrent.ExecutionException;
import java.util.logging.Logger;

import org.apache.kafka.clients.CommonClientConfigs;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.KafkaException;
import org.apache.kafka.common.config.SaslConfigs;
import org.apache.kafka.common.config.SslConfigs;
import org.apache.kafka.common.serialization.StringSerializer;


/** Producer class generated by the Event Streams sample producer generator.  I've left as-is, except for
 *  adding the Apache license, renaming the class, switching from log4j to java.util.logging, and renaming
 *  the two environment variables to conform to my naming conventions.
 *
 * Note that rumor is that Open Liberty is about to add support for mpReactiveMessaging-3.0, perhaps in their
 * 23.0.0.12 release (or if not, hopefully early in 2024).  Once that happens, this class will be replaced
 * by use of its org.eclipse.microprofile.reactive.messaging.Emitter that will be able to be injected via CDI.
 */
public class EventStreamsProducer {

    private final String topic;
    private final String API_KEY  = System.getenv("KAFKA_API_KEY");
    private String USERNAME = System.getenv("KAFKA_USER");
    private String SASL_MECHANISM = System.getenv("MP_MESSAGING_CONNECTOR_LIBERTY_KAFKA_SASL_MECHANISM");
    private String SASL_JAAS_CONFIG = System.getenv("MP_MESSAGING_CONNECTOR_LIBERTY_KAFKA_SASL_JAAS_CONFIG");

    private KafkaProducer<String, String> kafkaProducer;
    
    private Logger logger = Logger.getLogger(EventStreamsProducer.class.getName());

    public EventStreamsProducer(String bootstrapServerAddress, String topic) throws InstantiationException {
        this.topic = topic;
        if (topic == null) {
            throw new InstantiationException("Missing required topic name.");
        } else if (bootstrapServerAddress == null) {
            throw new InstantiationException("Missing required bootstrap server address.");
        }
        try {
            kafkaProducer = createProducer(bootstrapServerAddress);
        } catch (KafkaException e) {
            throw new InstantiationException(e.getMessage());
        }
    }
    
    private KafkaProducer<String, String> createProducer(String brokerList) {
        //provide defaults if not customized via environment variables
        if (USERNAME==null) USERNAME = "token";
        if (SASL_MECHANISM==null) SASL_MECHANISM = "PLAIN";
        if (SASL_JAAS_CONFIG==null) SASL_JAAS_CONFIG = "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"" + USERNAME + "\" password=\"" + API_KEY + "\";";

        Properties properties = new Properties();
        //common Kafka configs
        properties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerList);
        properties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
        properties.put(SaslConfigs.SASL_MECHANISM, SASL_MECHANISM);
        properties.put(SaslConfigs.SASL_JAAS_CONFIG, SASL_JAAS_CONFIG);
        properties.put(SslConfigs.SSL_PROTOCOL_CONFIG, "TLSv1.2");
        properties.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, "TLSv1.2");
        properties.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, "HTTPS");
        //Kafka producer configs
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.CLIENT_ID_CONFIG, "stocktrader-producer");
        properties.put(ProducerConfig.ACKS_CONFIG, "all");
        properties.put(ProducerConfig.CLIENT_DNS_LOOKUP_CONFIG,"use_all_dns_ips");

        KafkaProducer<String, String> kafkaProducer = null;
        
        try {
            kafkaProducer = new KafkaProducer<>(properties);
        } catch (KafkaException kafkaError ) {
            logger.warning("Error while creating producer: "+kafkaError.getMessage());
            Throwable cause = kafkaError.getCause();
            if (cause != null) logger.warning("Caused by: "+cause.getMessage());
            StringWriter stringWriter = new StringWriter();
            PrintWriter printWriter = new PrintWriter(stringWriter);
            properties.list(printWriter);
            logger.warning("KafkaProducer properties: "+stringWriter.toString());
            throw kafkaError;
        }
        return kafkaProducer;
    }

    public RecordMetadata produce(String message) throws InterruptedException, ExecutionException, ConnectException {
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, null, message);
        RecordMetadata recordMetadata = kafkaProducer.send(record).get();
        return recordMetadata;
    }

    public void shutdown() {
        kafkaProducer.flush();
        kafkaProducer.close();
    }
}
